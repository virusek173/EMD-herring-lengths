---
title: "Herringmania"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)

#install.packages("ggcorrplot") # Tylko przy 1szym odpaleniu
library(ggcorrplot)
```

## Wstępna analiza danych

##### Wczytanie danych oraz określenie rozmiaru:
```{r dplyr}
fileName = "data/sledzie.csv"
herrings = read.csv(fileName, header = TRUE, sep = ",", dec = ".")
dimentions <- dim(herrings)
dimentions
```
Mamy do czynienia z danymi mającymi 16 zmiennych oraz 52582 przypadków do analizy.

##### Wypisanie nazw kolumn oraz pierwszego wiersza:
```{r}
head(herrings, n=1)
```
Widzimy, że z powodu braku nazwy pierwszej kolumny, została ona zastąpiona znakiem X. Akceptujemy to uzupełnienie pamiętając, aby w przyszłości odwoływać się właśnie do tego znaku.

##### Zamiana znaku "?" reprezentującego pustą wartość na <NA>:
```{r}
#herrings <- head(herrings, 6)
herrings[herrings == "?"] <- NA
```

##### Sprawdzenie ile jest pustych wartości w każdej kolumnie:
```{r}
countNa <- sapply(herrings, function(x) sum(is.na(x)))
countNa
```

##### Sprawdzenie ile jest pustych wartości razem:
```{r}
sumCountNa <- sum(countNa)
sumCountNa
```

##### Sprawdzenie ile jest wierszy z pustymi wartościami. Wzięliśy pod uwagę tylko prawdopodobne kolumny:
```{r}
countBlackRows <- function(data) {
  blankRows <- data %>% filter(is.na(cfin1) | is.na(cfin2) | is.na(chel1) | is.na(chel2) | is.na(lcop1) | is.na(lcop2) | is.na(sst))
  blankRowsNumber <- count(blankRows)
  blankRowsNumber
}

blankRowsNumber <- countBlackRows(herrings)
blankRowsNumber
```
Tym razem Wyszło nam mniej niż w przypadku zsumowania wszytkich zer. Różnica ta wynika z tego, że niektóre wiersze mają więcej pustych wartości niż jedną.

##### Sprawdzenie ile procent całości zajumją :
```{r}
percentage <- blankRowsNumber/dimentions[1] * 100
round(percentage, 2)
```
Na podstaiwe powyższych obserwacji, zdecydowaliśmy się nie usuwać wierszy z pustymi wartościami, ponieważ usuniemy wtedy aż 19.2% całości danych. Taka ilość usuniętych danych na pewno wpłynęła by na wynik analizy zbioru. 

Ponieważ wartości z kolumn z ubytkami powtarzają się wielokrotnie, postanowiliśmy zastosować prostą technikę, polegającą na zastąpieniu brakujących danych, wartościami sąsiednimi.

##### Zastąpienie ubytków w danych sąsiednią wartością:
```{r}
completeData <- herrings %>% mutate(
  cfin1 = case_when((is.na(cfin1) & !is.na(lag(cfin1))) ~ lag(cfin1), is.na(cfin1) ~ lead(cfin1), TRUE ~ cfin1),
  cfin2 = case_when((is.na(cfin2) & !is.na(lag(cfin2))) ~ lag(cfin2), is.na(cfin2) ~ lead(cfin2), TRUE ~ cfin2),
  chel1 = case_when((is.na(chel1) & !is.na(lag(chel1))) ~ lag(chel1), is.na(chel1) ~ lead(chel1), TRUE ~ chel1),
  chel2 = case_when((is.na(chel2) & !is.na(lag(chel2))) ~ lag(chel2), is.na(chel2) ~ lead(chel2), TRUE ~ chel2),
  lcop1 = case_when((is.na(lcop1) & !is.na(lag(lcop1))) ~ lag(lcop1), is.na(lcop1) ~ lead(lcop1), TRUE ~ lcop1),
  lcop2 = case_when((is.na(lcop2) & !is.na(lag(lcop2))) ~ lag(lcop2), is.na(lcop2) ~ lead(lcop2), TRUE ~ lcop2),
  sst = case_when((is.na(sst) & !is.na(lag(sst))) ~ lag(sst), is.na(sst) ~ lead(sst), TRUE ~ sst)
)


blankRowsNumber <- countBlackRows(completeData)
blankRowsNumber
```
Widzimy, że zastąpienie wartości uzupełniło nam większość danych, ale nadal mamy 9 komórek bez wartości. Taką liczbę możemy już spokojnie usunąć.

##### Usunięcie pozostałych wierszy:
```{r}
completeData <- completeData %>% filter_all(all_vars(!is.na(.)))

blankRowsNumber <- countBlackRows(completeData)
blankRowsNumber
```
Teraz już mamy kompletne dane, bez pustych wartości. Możemy zatem kontynuaować przetwarzanie.

###### Zauważyliśmy, że większość danych w ramach jednego łowiska są identyczne, więc pogrupowaliśmy je po tych danych:
```{r}
groupedData <- completeData %>% group_by(cfin1, cfin2, chel1, chel2, lcop1, lcop2, fbar, recr, cumf, totaln, sst, sal, nao)
groupedData
```
W taki sposób uzyskaliśmy pogrupowane dane do 557 wierszy, liczba ta powinna odpowiadać iości łowisk.

##### Funkcja mapująca indeks na rok:
```{r}
mapIndexToYear <- function(index) {
  maxIndex <- dim(herrings)[1]
  
  year = (index*60)/maxIndex
  as.integer(year)
  
}

mapIndexToYear(40000)
```
##### Wykres zależności rozmiaru śledzia w analizowanych latach:
```{r}
#completeData[["X"]]
plot(mapIndexToYear(groupedData[["X"]]), groupedData[["length"]], cex = 0.5, main = "Wykres zależności rozmiaru śledzia w analizowanych latach", xlab = "Kolejne lata", ylab = "Rozmiar śledzia")
```


## Rozkład wartości kolumn

##### Stworzenie wykresu rozkładu dla każdej ze zmiennych:

```{r}
legend <- c(
    "indeks obserwacji - X",
    "length: długość złowionego śledzia [cm]",
    "cfin1: dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 1]",
    "cfin2: dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 2]",
    "chel1: dostępność planktonu [zagęszczenie Calanus helgolandicus gat. 1]",
    "chel2: dostępność planktonu [zagęszczenie Calanus helgolandicus gat. 2]",
    "lcop1: dostępność planktonu [zagęszczenie widłonogów gat. 1]",
    "lcop2: dostępność planktonu [zagęszczenie widłonogów gat. 2]",
    "fbar: natężenie połowów w regionie [ułamek pozostawionego narybku]",
    "recr: roczny narybek [liczba śledzi]",
    "cumf: łączne roczne natężenie połowów w regionie [ułamek pozostawionego narybku]",
    "totaln: łączna liczba ryb złowionych w ramach połowu [liczba śledzi]",
    "sst: temperatura przy powierzchni wody [°C]",
    "sal: poziom zasolenia wody [Knudsen ppt]",
    "xmonth: miesiąc połowu [numer miesiąca]",
    "nao: oscylacja północnoatlantycka [mb]")

names <- names(groupedData)
df <- sapply(groupedData[, c(1:16)], as.numeric)

for (x in c(1:4)){
  layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))
  for (i in c(1:4)) {
    hist(df[,4*x + i - 4],
    main= paste(" ",legend[4*x + i - 4]),
    cex.main = 0.62,
    xlab=names[4*x + i - 4],
    ylab = "% Liczności",
    col="darkmagenta",
    freq=FALSE
    )
  }
}

```

Niektóre rozkłady danych z jednej kategorii (kolumny) przypominają rozkład normlany mi. dane: długości śledzia, poziomu zasolenia wody czy miesiąca połowu.

##### TODO skomentowac najdziwniejsze anomalie na wykresach

## Korelacja pomiędzy zmiennym

Ważnym czynnikiem jest także zbadanie korelacji pomiędzy poszczególnym,i zmiennymi

```{r }
res <- round(cor(df),2)
print(ggcorrplot(res, method = "circle"))
```
Powyższa macierz korelacji przedstawia zależności pomiędzy każdą parą zmiennych. Przyjęty próg ważności obserwacji wynosi < -0.4 oraz > 0.4.
Przefiltrujmy macierz i zobaczmy które z par należą do przedziału ważności.

##### Filtracja głównie skorelowanych zmiennych pozyskanych z macierzy korelacji:

```{r}
pos_cor <- c(sort(unique(res[res > 0.4 & res != 1.0])))
neg_cor <- c(sort(unique(res[res < -0.4 & res != 1.0])))
```
Znalezione wartości korelacji pozytywnej przekraczające próg:
```{r}
pos_cor
```
Znalezione wartości korelacji negatywnej przekraczające próg:
```{r}
neg_cor
```

Chcielbyśmy zobaczyć które pary zmiennych kryją się za odpowiednio wysokimi(niskimi) wartościami korelacji. W tym celu tworzymy funkcję która znajdzie szukaną parę.

```{r}
show_pairs <- function(cor) {
  pairs <- matrix(ncol = 2)
  for (i in cor){
    a = which(res==i, arr.ind=TRUE)
    pairs = rbind(pairs, c(rownames(a)[1],rownames(a)[2]))
  }
  pairs = pairs[-1,]
  return(pairs)
}

positive <- show_pairs(pos_cor)
negative <- show_pairs(neg_cor)
```

Znalezione pary pozytywnej korelacji:
```{r}
positive
```
Znalezione pary negatywnej korelacji:
```{r}
negative
```

##### Analiza skorelowanych elementów:

Pomijamy autokorelację zmiennych (widoczną na przekątnej jako czerwone koło).

##### Z wykresu możemy zaobserwować wyróżniające się pary dodatniej korelacji:
1. Wsp. kor: 0.40 cfin1:cfin2 (dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 1] -  dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 2])
2. Wsp. kor: 0.41 nao:X (oscylacja północnoatlantycka - indeks obserwacji)
3. Wsp. kor: 0.52 nao:sst (oscylacja północnoatlantycka - temperatura przy powierzchni wody)
4. Wsp. kor: 0.64 lcop1:chel1 (dostępność planktonu [zagęszczenie widłonogów gat. 1 - zagęszczenie Calanus helgolandicus gat. 1]
5. Wsp. kor: 0.69 lcop2:chel2 (dostępność planktonu [zagęszczenie widłonogów gat. 2 - zagęszczenie Calanus helgolandicus gat. 2]
6. Wsp. kor: 0.81 cumf:fbar (łączne roczne natężenie połowów w regionie [ułamek pozostawionego narybku] - natężenie połowów w regionie [ułamek pozostawionego narybku])

##### Ocena korelacji:
1. Dostępność planktonu Calanus finmarchicus gat 1 jest zależna od planktonu tego samego rodzaju planktonu gat. 2.
2. Wzmożona oscylacja północnoatlantycka jest powiązana ze wzrostem indeksu obserwacji. Korzystając z wiedzy, że obserwacje posortowane są chronologicznie można stwierdzić że oscylacja rośnie wraz z czasem. 
3. Wzmożona oscylacja północnoatlantycka jest powiązana ze wzrostem temperatury wody przy powierzchni.
4. Dostępność planktonu widłonogów gat 1. jest zależna od występnowania helgolandicus gat. 1. Gatunki te często występują razem. 
5. Analogicznie jak pkt. 4 w przypadku gatunku nr 2 obu planktonów.
6. Natężenie regionalne jest składową całościowego natężenia stąd wysoka korelacja jest czymś spodziewanym.

##### Wyróżniające się pary ujemnej korelacji:
7. Wsp. kor: -0.42 sst:length (temperatura przy powierzchni wody - długość złowionego śledzia)
8. Wsp. kor: -0.50 totaln:fbar (łączna liczba ryb złowionych w ramach połowu - natężenie połowów w regionie)
9. Wsp. kor: -0.70 totaln:cumf (łączna liczba ryb złowionych w ramach połowu - łączne roczne natężenie połowów w regionie [ułamek pozostawionego narybku])

###### Ocena korelacji:
7. Im temperatura wody jest cieplejsza tym wyławiany śledź jest mniejszy. Analogicznie gdy tempeatura wody spada, średnia długość śledzia rośnie.
8. Im większe regionalne natężenie połowów w regionie, tym mniejsza jest liczba ryb łowionych w ramach połowu.
9. Im większe całkowite natężenie połowów w regionie, tym mniejsza jest liczba ryb łowionych w ramach połowu.
 
##### Filtracja zmiennych znacząco skorelowanych:

Można sprawdzić także jak wyglądają nieco mniej skorelowane wartości np. w przedziale (-0.4:-0.3) or (0.3:0.4):
```{r}
pos_cor <- c(sort(unique(res[res > 0.3 & res < 0.4])))
neg_cor <- c(sort(unique(res[res < -0.3 & res > -0.4])))

softly_pos <- show_pairs(pos_cor)
softly_neg <- show_pairs(neg_cor)
```

Znalezione pary pozytywnej korelacji:
```{r}
softly_pos
```
Znalezione pary negatywnej korelacji:
```{r}
softly_neg
```

##### Ocena korelacji:

Przeglądając zbiór nieco mniej skorelowanych zmiennych można zauważyć, że średnia temperatura wody rośnie z czasem. Z drugiej strony liczba wyławianych śledzi jak i ich długość maleje z czasem. Ponadto rosnąca oscylacja atlantycka ma wpływ na zmniejszenie się zagęszczenia planktonu widłonogów gat. 2, Calanus helgolandicus gat. 2 oraz liczby wyławianych śledzi.

## Obserwacje po łącznej analizie rozkładu danych i macierzy korelacji

  -


## Konstrukcja regresora

##### Podział zbioru danych na treningowy testowy i walidacyjny
```{r}


```


## Ewaluacja wyników miara R^2 i RMSE 
```{r}
#dumb data
obs <- 1:5
mod <- c(0.8,2.4,2,3,4.8)

rsq <- function(x, y) summary(lm(y~x))$r.squared
rmse <- function(m, o) sqrt(mean((m - o)^2))

R2 <- rsq(obs, mod)
RMSE_v <- rmse(mod, obs)
```
Wynik ewaluacji miarą R^2
```{r}
round(R2,3)
```
Wynik ewaluacji miarą RSME
```{r}
round(RMSE_v,3)
```


